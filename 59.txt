How Data Analytics and AI are used to halt the COVID-19 Pandemic?

Artificial IntelligenceBlackcofferBusiness AnalyticsWhat We Think How Data Analytics and AI are used to halt the COVID-19 Pandemic?

April 30, 2021 5435 














Even though COVID-19 has not yet halted and we are facing the nth wave of the coronavirus outbreak across several countries, most notably the US, India, and Brazil. It is a fact that Data Analytics and AI are the big guns of our artillery in this fight against the COVID-19 pandemic. It has helped us in several stages of this outbreak, like the detection of its first outbreak, vaccine development and manufacturing contact tracing, and future hotspot detection. Some of these interesting applications are discussed in this article.
A lesser-known fact is that the COVID-19 outbreak was first detected in Toronto, Canada, nearly 7,230 miles away from the first outbreak, nine days before the WHO issued its warning. It was with the help of Big Data Analytics and AI, more specifically Deep Learnings (DL, a subset of Machine Learning) application in Natural Language Processing (NLP) to analyze text inputs that traced the surge of pneumonia cases in the Wuhan province of China. The specialty of DL algorithms is that they mimic the brain cells called neurons and can identify patterns in Big Data. This DL-backed software is used as inputs, reports from public health organizations, global airline ticketing data, etc. These were used to flag unusual surges and potential spreads of infectious diseases.
The next application of Big Data Analytics and AI was in the Research and Development of drugs to halt COVID-19. AI was used to analyze the protein structure of the virus, findings that were significant in the progress of vaccine development. In preliminary studies, it was found that it does not mutate as fast as other viruses such as HIV, which means that a prophylactic vaccine is a better way to proceed rather than a therapy. But there is also some evidence supporting the fact that when we find any kind of cure for it, there is a chance of the virus mutating, which is what happened and major mutations have been found in the UK, Brazil, and South Africa. AI also assisted scientists in rapidly shortlisting a set of already available vaccines that could be effective against the coronavirus.
Another interesting application of AI can be found in the selection of the right candidates, i.e. most likely to test positive for testing coronavirus in case of insufficient testing resources. This method was first exercised on Greek borders and was called project EVA. Whenever a traveler wanted to come into Greece, he had to fill out a form known as Passenger Locator Form (PLF) at least 24 hours prior to arrival, containing information on their origin country, demographics, point, and date of entry, and the intended destination. EVA then allocated testing resources according to the size of the set of passengers to be tested. After the test results, if found positive, they are put in quarantine. The results were sent back to the program for real-time learning.
The question remains how EVA made allocations, It was found that, statistically, only the origin country and the city were significant factors for screening. Ultimately, from a variety of countries and city pairs, EVA had to predict how many testing resources were to be allocated at each entry point and to particular passengers from a location is technically called the Multi-Armed Bandit (MAB) problem, and the chosen method to solve this problem was an AI algorithm called optimistic Gittins index. This algorithm identified on average 1.85x as many asymptomatic, infected travelers as random surveillance testing, and up to 2-4x as many during peak travel. After the test results, if found positive, they are put in quarantine. Following the collection of significant data through the aforementioned process, after a certain period, policies were made categorizing them separately and imposing restrictions on travelers from the specific location. This EVA as presented above was in operation from August 6th to November 1st processing around 38,500 PLFs each day and testing on an average 18.5% of households entering the country every day.
Above mentioned applications just show the tip of the iceberg and there is more to get into some of the other developments to watch for include the use of Image Recognition to identify covid based on x-ray images, the use of Deep Learning to predict the 3-D protein structure associated with COVID-19 and so on.
Blackcoffer Insights 27: Aniruddha Surse, NIT Nagpur



TAGSAlgorithmsArtificial IntelligenceBig Data AnalyticsCoronavirusCOVID-19deep learningmachine learningMulti-Armed Bandit (MAB) problemNatural Language Processingnlp 
Previous articleSolution for Contact Centre ProblemsNext articleEnvironmental impact of the COVID-19 pandemic â€“ Lesson for the Future Ajay Bidyarthy  
RELATED ARTICLESMORE FROM AUTHOR




 What We Think 

Rise of telemedicine and its Impact on Livelihood by 2040 

 



 What We Think 

Rise of e-health and its impact on humans by the year 2030 

 



 What We Think 

Rise of e-health and its impact on humans by the year 2030 

  

 





- Advertisement -MOST POPULAR INSIGHTS




Is telehealth the future of healthcare? 
April 28, 2022 


 




Google Local Service Ads Missed Calls and Messages Automation Tool 
August 30, 2021 


 




HR Analytics Dashboard 
October 3, 2020 


 




How Data Analytics can help your business respond to the impact... 
May 1, 2021 


 Load more RECOMMENDED INSIGHTS



 What We Think 
What patients like and dislike about telemedicine?

 



 Our Success Stories 
A Leading Musical Instrumental, Website SEO & Optimization

 



 What We Do 
Google Local Service Ads LSA API To Google BigQuery to Google...

 



 What We Think 
Impacts of COVID 19 on Food products